{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "from scipy.fftpack import fft\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import precision_score\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "legal_labels = 'yes no up down left right on off stop go silence unknown'.split()\n",
    "train_data_path = Path('./train/audio')\n",
    "valid_subset_path = Path('./train/validation_list.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip2(values):\n",
    "    a, b = zip(*values)\n",
    "    return list(a), list(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoundDataset(Dataset):\n",
    "    def __init__(self, directory, subset_path=None, transform=None):\n",
    "        self.directory = directory\n",
    "        self.transform = transform\n",
    "        self._subset = self._load_subset(subset_path) if subset_path else None\n",
    "        self._labels, self._sounds = self._list_of_wavs(directory)\n",
    "        self._transformed_labels = self._transform_labels(self._labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        label, sound = self._labels[idx], self._sounds[idx]\n",
    "        sample_rate, samples = wavfile.read(self.directory/label/sound)\n",
    "        label = self._transformed_labels[idx]\n",
    "        sample = {'sample_rate': sample_rate, 'samples': samples, 'label': label}\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample\n",
    "    \n",
    "    def _is_needed(self, name):\n",
    "        return (name in self._subset) if self._subset is not None else True\n",
    "    \n",
    "    def _list_of_wavs(self, directory, ext='wav'):\n",
    "        return unzip2(path.parts[-2:] for path in directory.glob(f'*/*.{ext}') if self._is_needed(path.parts[-1]))\n",
    "    \n",
    "    @staticmethod\n",
    "    def _load_subset(file):\n",
    "        return set(path.split('/')[1] for path in file.read_text().split('\\n'))\n",
    "    \n",
    "    @staticmethod\n",
    "    def _transform_labels(labels):\n",
    "        nlabels = []\n",
    "\n",
    "        for label in labels:\n",
    "            if label == '_background_noise_':\n",
    "                nlabels.append('silence')\n",
    "            elif label not in legal_labels:\n",
    "                nlabels.append('unknown')\n",
    "            else:\n",
    "                nlabels.append(label)\n",
    "\n",
    "        return np.array(pd.get_dummies(pd.Series(nlabels)), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomChop:\n",
    "    def __init__(self, length=16_000):\n",
    "        self.length = length\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        sample_rate, samples, label = sample['sample_rate'], sample['samples'], sample['label']\n",
    "        samples = self._pad_audio(samples)\n",
    "        \n",
    "        if len(samples) > self.length:\n",
    "            samples = self._chop_audio(samples)\n",
    "        \n",
    "        return {'sample_rate': sample_rate, 'samples': samples, 'label': label}\n",
    "            \n",
    "    def _pad_audio(self, samples):\n",
    "        if len(samples) >= self.length: \n",
    "            return samples\n",
    "\n",
    "        return np.pad(samples, pad_width=(self.length - len(samples), 0), mode='constant', constant_values=(0, 0))\n",
    "\n",
    "    def _chop_audio(self, samples):\n",
    "        start = np.random.randint(0, len(samples) - self.length)\n",
    "        return samples[start : start + self.length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Specgram:\n",
    "    def __init__(self, sample_rate=8_000):\n",
    "        self.sample_rate = sample_rate\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        sample_rate, samples, label = sample['sample_rate'], sample['samples'], sample['label']\n",
    "        resampled = signal.resample(samples, int(self.sample_rate / sample_rate * samples.shape[0]))\n",
    "        _, _, specgram = self._log_specgram(resampled, sample_rate=self.sample_rate)\n",
    "        specgram = specgram.reshape(1, specgram.shape[0], specgram.shape[1])\n",
    "        return {'samples': specgram, 'label': label}\n",
    "        \n",
    "    @staticmethod\n",
    "    def _log_specgram(audio, sample_rate, window_size=20, step_size=10, eps=1e-10):\n",
    "        nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "        noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "        freqs, times, spec = signal.spectrogram(audio,\n",
    "                                                fs=sample_rate,\n",
    "                                                window='hann',\n",
    "                                                nperseg=nperseg,\n",
    "                                                noverlap=noverlap,\n",
    "                                                detrend=False)\n",
    "\n",
    "        return freqs, times, np.log(spec.T.astype(np.float32) + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor:\n",
    "    def __call__(self, sample):\n",
    "        samples, label = sample['samples'], sample['label']\n",
    "        return {'samples': torch.from_numpy(samples), 'label': torch.from_numpy(label)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([RandomChop(), Specgram(), ToTensor()])\n",
    "train_dataset = SoundDataset(train_data_path, transform=data_transform)\n",
    "valid_dataset = SoundDataset(train_data_path, valid_subset_path, transform=data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=32, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = nn.Dropout(p=0.30)\n",
    "\n",
    "\n",
    "class ConvRes(nn.Module):\n",
    "    def __init__(self, insize, outsize):\n",
    "        super(ConvRes, self).__init__()\n",
    "        \n",
    "        self.math = nn.Sequential(\n",
    "            nn.BatchNorm2d(insize),\n",
    "            torch.nn.Conv2d(insize, outsize, kernel_size=2, padding=2),\n",
    "            nn.PReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.math(x)\n",
    "\n",
    "\n",
    "class ConvCNN(nn.Module):\n",
    "    def __init__(self, insize, outsize, kernel_size=7, padding=2, pool=2, avg=True):\n",
    "        super(ConvCNN, self).__init__()\n",
    "        self.avg = avg\n",
    "        self.math = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(insize, outsize, kernel_size=kernel_size, padding=padding),\n",
    "            torch.nn.BatchNorm2d(outsize),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.MaxPool2d(pool, pool),\n",
    "        )\n",
    "        self.avgpool = torch.nn.AvgPool2d(pool, pool)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.math(x)\n",
    "        \n",
    "        if self.avg is True:\n",
    "            x = self.avgpool(x)\n",
    "            \n",
    "        return x\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    " \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        self.cnn1 = ConvCNN(1, 32, kernel_size=7, pool=4, avg=False)\n",
    "        self.cnn2 = ConvCNN(32, 32, kernel_size=5, pool=2, avg=True)\n",
    "        self.cnn3 = ConvCNN(32, 32, kernel_size=5, pool=2, avg=True)\n",
    "\n",
    "        self.res1 = ConvRes(32, 64)\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            self.cnn1, \n",
    "            dropout,\n",
    "            self.cnn2,\n",
    "            self.cnn3,\n",
    "            self.res1,\n",
    "        )\n",
    "\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            nn.Linear(1024, 12),\n",
    "        )\n",
    "        self.sig = nn.Sigmoid()\n",
    "  \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.005\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "model = Net()\n",
    "loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=5e-5) #  L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, dataloader, log_steps=250):\n",
    "    n_total = dataloader.batch_size * len(dataloader)\n",
    "    last_batch = len(dataloader)\n",
    "    \n",
    "    loss_history = []\n",
    "    loss_batch_history = []\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, batch in enumerate(dataloader, 1):\n",
    "        data, target = Variable(batch['samples']), Variable(batch['label'])\n",
    "                 \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(data)\n",
    "        loss = loss_func(preds, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_batch_history.append(loss.data[0])\n",
    "            \n",
    "        if batch_idx % log_steps == 0 or batch_idx == last_batch:\n",
    "            loss_history.append(np.mean(loss_batch_history))\n",
    "            loss_batch_history = []\n",
    "            \n",
    "            n_samples = min(batch_idx * dataloader.batch_size, n_total)\n",
    "            progress = 100. * n_samples / n_total\n",
    "            print(f'Train Epoch: {epoch} [{n_samples}/{n_total} ({progress:.0f}%)]\\tLoss: {loss.data[0]:.6f}')\n",
    "    \n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train Epoch: 1 [8000/64736 (12%)]\tLoss: 0.118003\n",
      "Train Epoch: 1 [16000/64736 (25%)]\tLoss: 0.097058\n",
      "Train Epoch: 1 [24000/64736 (37%)]\tLoss: 0.084505\n",
      "Train Epoch: 1 [32000/64736 (49%)]\tLoss: 0.044929\n",
      "Train Epoch: 1 [40000/64736 (62%)]\tLoss: 0.086806\n",
      "Train Epoch: 1 [48000/64736 (74%)]\tLoss: 0.030243\n",
      "Train Epoch: 1 [56000/64736 (87%)]\tLoss: 0.105790\n",
      "Train Epoch: 1 [64000/64736 (99%)]\tLoss: 0.046144\n",
      "Train Epoch: 1 [64736/64736 (100%)]\tLoss: 0.073868\n",
      "Epoch 2\n",
      "Train Epoch: 2 [8000/64736 (12%)]\tLoss: 0.049021\n",
      "Train Epoch: 2 [16000/64736 (25%)]\tLoss: 0.085625\n",
      "Train Epoch: 2 [24000/64736 (37%)]\tLoss: 0.036965\n",
      "Train Epoch: 2 [32000/64736 (49%)]\tLoss: 0.041786\n",
      "Train Epoch: 2 [40000/64736 (62%)]\tLoss: 0.035610\n",
      "Train Epoch: 2 [48000/64736 (74%)]\tLoss: 0.061512\n",
      "Train Epoch: 2 [56000/64736 (87%)]\tLoss: 0.049652\n",
      "Train Epoch: 2 [64000/64736 (99%)]\tLoss: 0.074203\n",
      "Train Epoch: 2 [64736/64736 (100%)]\tLoss: 0.036081\n",
      "Epoch 3\n",
      "Train Epoch: 3 [8000/64736 (12%)]\tLoss: 0.074172\n",
      "Train Epoch: 3 [16000/64736 (25%)]\tLoss: 0.023396\n",
      "Train Epoch: 3 [24000/64736 (37%)]\tLoss: 0.064404\n",
      "Train Epoch: 3 [32000/64736 (49%)]\tLoss: 0.067335\n",
      "Train Epoch: 3 [40000/64736 (62%)]\tLoss: 0.054642\n",
      "Train Epoch: 3 [48000/64736 (74%)]\tLoss: 0.059723\n",
      "Train Epoch: 3 [56000/64736 (87%)]\tLoss: 0.036466\n",
      "Train Epoch: 3 [64000/64736 (99%)]\tLoss: 0.021839\n",
      "Train Epoch: 3 [64736/64736 (100%)]\tLoss: 0.064098\n",
      "Epoch 4\n",
      "Train Epoch: 4 [8000/64736 (12%)]\tLoss: 0.022153\n",
      "Train Epoch: 4 [16000/64736 (25%)]\tLoss: 0.030509\n",
      "Train Epoch: 4 [24000/64736 (37%)]\tLoss: 0.051325\n",
      "Train Epoch: 4 [32000/64736 (49%)]\tLoss: 0.075605\n",
      "Train Epoch: 4 [40000/64736 (62%)]\tLoss: 0.058131\n",
      "Train Epoch: 4 [48000/64736 (74%)]\tLoss: 0.021657\n",
      "Train Epoch: 4 [56000/64736 (87%)]\tLoss: 0.024090\n",
      "Train Epoch: 4 [64000/64736 (99%)]\tLoss: 0.087801\n",
      "Train Epoch: 4 [64736/64736 (100%)]\tLoss: 0.050098\n",
      "CPU times: user 1h 7min 23s, sys: 8min 24s, total: 1h 15min 47s\n",
      "Wall time: 56min 4s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "loss_history = []\n",
    "\n",
    "for epoch in range(1, 5):\n",
    "    print(\"Epoch %d\" % epoch)\n",
    "    loss_history += train(epoch, train_dataloader)\n",
    "    \n",
    "plt.plot(loss_history);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader):\n",
    "    y_true = np.zeros(0)\n",
    "    y_pred = np.zeros(0)\n",
    "    \n",
    "    for batch_idx, batch in enumerate(dataloader, 1):\n",
    "        data, target = Variable(batch['samples']), batch['label'].numpy()     \n",
    "        y_true = np.concatenate((y_true, np.argmax(target, axis=1)))\n",
    "        y_pred = np.concatenate((y_pred, np.argmax(model(data).data.numpy(), axis=1)))\n",
    "    \n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = evaluate(valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.520\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(y_true, y_pred, average='macro')\n",
    "print(f'Precision: {precision: 0.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
